{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "MNE-Python data-structures are based around `FIF file format` from `Neuromag`.\n",
    "\n",
    "EEG and MEG data from a subject performing an audiovisual experiment, along with MRI scans for that subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(\n",
    "    sample_data_folder,\n",
    "    'MEG',\n",
    "    'sample',\n",
    "    'sample_audvis_filt-0-40_raw.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif(sample_data_raw_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SSP Projector:**\n",
    "A projector (abbr. proj), also referred to as Signal Space Projection (SSP), defines a linear operation applied spatially to EEG or MEG data. You can see this as a matrix multiplication that reduces the rank of the data by projecting it to a lower dimensional subspace. Such a projection operator is applied to both the data and the forward operator for source localization. Note that EEG average referencing can be done using such a projection operator. It is stored in the measurement info in info['projs'].\n",
    "\n",
    "[Background on projectors and projections](https://mne.tools/dev/auto_tutorials/intro/plot_40_projectors_background.html#tut-projectors-background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Spectral Density (PSD) and raw traces for each sensor.\n",
    "For the PSD plot, we'll only plot frequencies below 50 Hz – data is low-pass filtered at 40 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(fmax=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(duration=5, n_channels=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Clean up data by performing independent component analysis (ICA). We'll skip the steps that helped determine which components that best capture the artifacts.\n",
    "[Repairing artifacts with ICA](https://mne.tools/dev/auto_tutorials/preprocessing/plot_40_artifact_correction_ica.html#tut-artifact-ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n",
    "ica.fit(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_properties(raw, picks=ica.exclude);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_raw = raw.copy()\n",
    "raw.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.apply(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some frontal channels to clearly illustrate the artifact removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chs = ['MEG 0111', 'MEG 0121', 'MEG 0131', 'MEG 0211', 'MEG 0221', 'MEG 0231',\n",
    "       'MEG 0311', 'MEG 0321', 'MEG 0331', 'MEG 1511', 'MEG 1521', 'MEG 1531',\n",
    "       'EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006',\n",
    "       'EEG 007', 'EEG 008']\n",
    "\n",
    "chan_idxs = [raw.ch_names.index(ch) for ch in chs]\n",
    "orig_raw.plot(order=chan_idxs, start=12, duration=4)\n",
    "raw.plot(order=chan_idxs, start=12, duration=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting experimental events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel='STI 014')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: sample number\n",
    "1: often ignored\n",
    "2: event ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3, 'visual/right': 4, 'smiley': 5, 'buttonpress': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mne.viz.plot_events(events, event_id=event_dict, sfreq=raw.info['sfreq']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoching continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_criteria = dict(mag=4000e-15, # 4000 fT\n",
    "                      grad=4000e-13, # 4000 fT/cm\n",
    "                      eeg=150e-6, # 150 uV\n",
    "                      eog=250e-6 # 250 uV\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(raw, events, event_id=event_dict, tmin=-0.2, tmax=0.5, reject=reject_criteria, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool across left/right stimulus presentations so we can compare auditory vs. visual responses. To avoid biasing signals to the left or right, we'll `equalize_event_counts` to randomly sample epochs from each condition to match the number of epochs present in the condition with the fewest good epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conds_we_care_about = ['auditory/left', 'auditory/right', 'visual/left', 'visual/right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.equalize_event_counts(conds_we_care_about) # this operates in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_epochs = epochs['auditory']\n",
    "vis_epochs = epochs['visual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw, epochs # free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show each epoch as one row of an image map, with color representing signal magnitude; the avg. evoked response and the sensor location are shown below the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_epochs.plot_image(picks=['MEG 1332', 'EEG 021']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-frequency analysis\n",
    "\n",
    "* time-frequency representations\n",
    "* power spectral density\n",
    "* cross-spectral density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the auditory epochs compute the induced power at different frequencies  and times using `Morlet wavelets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.arange(7, 30, 3)\n",
    "power = mne.time_frequency.tfr_morlet(aud_epochs, n_cycles=2, return_itc=False, freqs=frequencies, decim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.plot(['MEG 1332']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating evoked responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get estimate of evoked responses to auditory versus visual stimuli by averaging together the epochs in each condition, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_evoked = aud_epochs.average()\n",
    "vis_evoked = vis_epochs.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(dict(auditory=aud_evoked, visual=vis_evoked), show_legend='upper left', show_sensors='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining just the EEG channels, we'll see the classic auditory evoked N100-P200 pattern over dorso-frontal electrodes, the plot scalp topographies at some additional arbitrary times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_evoked.plot_joint(picks='eeg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_evoked.plot_topomap(times=[0., 0.08, 0.1, 0.12, 0.2], ch_type='eeg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining evoked responses to show contrast betwen conditions. Plot the difference wave at each sensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_diff = mne.combine_evoked([aud_evoked, -vis_evoked], weights='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_diff.pick_types('mag').plot_topo(color='r', legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the origins of the evoked activity by projecting the sensor data into the subject's `source space`. Here we'll use a minimum-norm estimation (MNE) to generate a continous map of activation contrained to the cortical surface. \n",
    "MNE uses a linear `inverse operator` to project EEG+MEG sensor measurements into the source space. The inverse operator is computed from the `forward solution` for this subject and estimate of `the covariance of sensor measurements`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inverse operator\n",
    "inverse_operator_file = os.path.join(sample_data_folder, 'MEG', 'sample', 'sample_audvis-meg-oct-6-meg-inv.fif')\n",
    "inverse_operator = mne.minimum_norm.read_inverse_operator(inverse_operator_file)\n",
    "\n",
    "# set SNR to compute regularization parameter (λ²)\n",
    "snr = 3.\n",
    "lambda2 = 1. / snr ** 2\n",
    "\n",
    "# generate the source time course (STC)\n",
    "stc = mne.minimum_norm.apply_inverse(vis_evoked, inverse_operator, lambda2=lambda2, method='MNE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to subjects' MRI files\n",
    "# subjects_dir = os.path.join(sample_data_folder, 'subjects')\n",
    "# stc.plot(initial_time=0.1, hemi='split', views=['lat', 'med'], subjects_dir=subjects_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
